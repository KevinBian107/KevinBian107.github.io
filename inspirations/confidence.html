<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Kaiwen Bian</title>

    <link rel="stylesheet" href="../stylesheets/styles.css">
    <link rel="stylesheet" href="../stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/KevinBian107/KevinBian107.github.io/main/assets/logo_3.png" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="../index.html" target="_blank">Statistics & Probability</a></h1>
        <div class="nav-list">
            <a href="../index.html" target="_blank">Home Page</a>
            <a href="../repo.html" class="nav-link">View Active GitHub Repo</a>
            <a href="../research.html" class="nav-link">Research</a>
            <a href="menu.html" class="nav-link">Wiki</a> <!-- keep all relative path -->
            <!-- <button onclick="showTranslateOptions()" class="custom-translate-button">Translate</button> -->
        </div>
        <blockquote>
          <p>Inspired by Prof.Carfagnini: "In math you either deal with equality equation or inequality equation, but sometimes they bridge"</p>
        </blockquote>
      </header>
      <section>

        <h1>Lend It Some Confidence</h1>

        <div class="profile">
          <img src="../assets/Profile_pic.jpeg" alt="Profile Picture">
          <div class="profile-details">
            <span class="name">Kaiwen Bian</span>
            <span class="metadata">5 min read · Jun 14, 2023</span>
          </div>
        </div>
        <p></p>

        <div id="google_translate_element" alt="Please use Google Chrome for translation"></div>
        <script type="text/javascript">
          // Initializes the Google Translate Element
          function googleTranslateElementInit() {
            new google.translate.TranslateElement({
              pageLanguage: 'en',
              includedLanguages: 'en,zh-CN,es,fr,de,ja,ru', // Restrict to English and Chinese Simplified
              layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
              autoDisplay: true  // Prevent automatic display of the dropdown
            }, 'google_translate_element');
          }
          // Function to manually trigger translation to Chinese
          function showTranslateOptions() {
            var selectField = document.querySelector(".goog-te-combo");
            if (selectField) {
              selectField.value = 'en,zh-CN,es,fr,de,ja,ru'; // Set the translation to Chinese
              selectField.dispatchEvent(new Event('change')); // Trigger the change event
            } else {
              console.error('Translation widget not loaded properly.');
            }
          }
          window.onload = function() {
                showTranslateOptions();
            };
          </script>          
        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
        <p></p>

        <p>
            Statistics is a very practical domain, but often tools in statistics have very deep mathamatical roots in probability theory. I found this to be quiet facinating because I think that only when understand the theoritical aspects of these tools will one be getting 
            an intuitive understanding of these tools and use/adapt them under appropriate circumstances. Things works for a mathamatical reason, they work because the math have happened to discover and support some things that happen to work.
        </p>

        <P>
            I want to use an concept that is very oftenly used through out many branches of statistics and probability to illustarte such point: <strong>Confidence Interval</strong>. It is so simple that probably a high school statistic class would discuss it but it is also so complex to 
            the point that one might not fully understand it until learning meausre theory in graduate school (for the record, I don't think I underatand it fully yet, but I can already see some of the intrinsic connections that makes it so amazing).
        </P>

        <p>
            The way I think about confidence interval is to reason why it is needed. I think the idea of needing it comes from statsistics with the question: can we do better than just giving a <strong>point estimate</strong> of what we believe about the true distribution? Can we give an <strong>interval estimate</strong>?
            Point estimate itself is a huge domain in statistics and probability (i.e. MOM, MLE,...), which we would not go into, but feel free to look into it a bit more as it is also very much rooted in probabilistic theory (i.e. MLE is maximizing the likelihood of observing all observatiosn in the same time, which are treated as independent and 
            identitically distributed random variable). Essentially an estimator is an random variable that tries to estimate the correct parameter for the given distribution to fit all the data. Okay, so we have an point estimator, but we want a range for it, so how about <strong>extracting and interval from the distribution 
            of this estimator</strong> since an estimator is techniqually an random variable. Let's look at the simple example when the estimator is \(\bar X\) or the mean of the sample. We know that:
            
            $$
            \bar X = \frac{x_1+...+x_n}{n}
            $$
            
            and that \(x_i\) approaches normal distribution \(N(\mu, \sigma)\), meaning that \(\bar X\) approaches \(N(\mu, \frac{\sigma}{\sqrt n})\) from probabilistic deriviation. 
            Then we can make an new random variable that approaches a standard normal distribution \(N(0,1)\):

            $$
            \frac{\bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1)
            $$

            This is an critical random varaibel here because we can now "extend" the estimator by giving it a interval. You may now have some intuition that these two seems to be weird values attached to the estimator does have a very probabilistic meaning since they look pretty similar.

            $$
            \bar{x} - z_{\frac{\alpha}{2}} \left(\frac{\sigma}{\sqrt{n}}\right), \bar{x} + z_{\frac{\alpha}{2}} \left(\frac{\sigma}{\sqrt{n}}\right)
            $$

            In fact, there is a deep conection between decision making hypothesis testing (HT) and confidence interval, known as the confidence interval duality where not rejecting the null hypothesis is teh equivalence with the confidence interval containing the real parameter. These connection list goes much longer, extending to some other 
            pretty well known distributions (you may have heard about \(T\) or \(X_n^2\) distribution).

            $$
            \left| \frac{\bar{X} - \mu_0}{\frac{\sigma}{\sqrt{n}}} \right| < z_{\alpha/2}
            $$

            If you are interested, here are some notes that goes deeper into these connections.
        </p>

        <a href="stat_connection.html" class="nav-link">
            <span class="link-icon">&#9881;</span> <!-- Unicode gear icon -->
            Some Notes on Basic Statistic/Probability Connections
        </a>
        <p></p>

      </section>
      <footer>
        <p>© 2024 Kaiwen Bian. All rights reserved.</p>
      </footer>
    </div>
    <script src="../javascripts/scale.fix.js"></script>
    <script src="../javascripts/translate.js"></script>
  </body>
</html>
