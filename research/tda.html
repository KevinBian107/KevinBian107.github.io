<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Kaiwen Bian</title>

    <link rel="stylesheet" href="../stylesheets/styles.css">
    <link rel="stylesheet" href="../stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/KevinBian107/KevinBian107.github.io/main/assets/index/logo_3.png" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

  </head>
  <body>
    <div class="wrapper_content_page">
      <header>
        <div class="nav-list">
            <a href="../index.html" class="nav-link">Home Page</a>
            <a href="../research.html" class="nav-link">Research</a>
            <a href="../idea.html" class="nav-link">Ideology</a>
            <a href="../projects.html" class="nav-link">Projects</a>
            <div id="google_translate_element"></div> <!-- Translator here -->
        </div>

      </header>
      <section>
        <h1>Connections Tells a story of Control</h1>
        <script type="text/javascript">
          // Initializes the Google Translate Element
          function googleTranslateElementInit() {
            new google.translate.TranslateElement({
              pageLanguage: 'en',
              includedLanguages: 'en,zh-CN,es,fr,de,ja,ru', // Restrict to English and Chinese Simplified
              layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
              autoDisplay: true  // Prevent automatic display of the dropdown
            }, 'google_translate_element');
          }
          // Function to manually trigger translation to Chinese
          function showTranslateOptions() {
            var selectField = document.querySelector(".goog-te-combo");
            if (selectField) {
              selectField.value = 'en,zh-CN,es,fr,de,ja,ru'; // Set the translation to Chinese
              selectField.dispatchEvent(new Event('change')); // Trigger the change event
            } else {
              console.error('Translation widget not loaded properly.');
            }
          }
          window.onload = function() {
                showTranslateOptions();
            };
          </script>          
        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

        <p></p>

        <p>
          We like to talk about and quantify things in Euclidean space, that's where our intuition works the best. However, most of the times it might be complicated trying to find the correct "metric" of understanding things in here. 
          Under such nice and structured space, we sometimes don't know how to talk about complex, yet interesting, data. However, as a <strong>“coordinate-free”</strong> method, computational topology 
          may provide us a new way to understand the <strong>shape of data</strong> in a more abstract but comprehensive way.
        </p>

        <div style="text-align: center;">
          <img src="../assets/research/tda_4.png" alt="TDA" style="width:90%; height:auto;">
          <blockquote>
            Image (both in cover & here) in curtesy of Yusu Wang: smooth & discerete Morse function for skeletonization of complex data
          </blockquote>
        </div>

        <p></p>

        <p>
          I am currently using computational topological method in prof. <a href="http://yusu.belkin-wang.org/" target="_blank">Yusu Wang</a>'s DSC 214 to try to understand what's truely happening inside the weight space of neural network when they are training upon specific tasks.
          Particularly, I am interested in seeing how the deep reinforcement learning in the <a href="/research/vnl.html">VNL system</a> may be interpreted from an computationaltopology perspective. Hopefully, we can better understand what is truly happening inside neural network, 
          what makes learning and what makes these learning comparable with biological neuronal data?</li>
          <ul>
            <li>What <strong>phenomenon</strong> is happening in the weight/intention world when we use a topological lens?</li>
            <li>How can building <strong>functional mappings</strong> across spaces just simulate something that is comparable with true neurons?</li>
            <li>What is the unique thing about these “good” connections (synaptice strength) that elicit realistic behaviors with activations (action potentials) compared with those that can't?</li>
            <li>If the connection is what matteres, then how does the connections tend to be <strong>organzied</strong> when trained?</li>

          </ul>
        </p>

        <p>
          <a href="https://github.com/KevinBian107/L-CTP" class="button">Codebase (closed repo now but will be open later)</a>
        </p>

        <p></p>

      </section>
      <footer>
        <!-- <p>© 2024 Kaiwen Bian. All rights reserved.</p> -->
      </footer>
    </div>
    <script src="../javascripts/scale.fix.js"></script>
    <script src="../javascripts/translate.js"></script>
    <script src="../javascripts/mode.js"></script>
  </body>
</html>
