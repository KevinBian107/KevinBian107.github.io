<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Kaiwen Bian</title>

    <link rel="stylesheet" href="../stylesheets/styles.css">
    <link rel="stylesheet" href="../stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/KevinBian107/KevinBian107.github.io/main/assets/index/logo_3.png" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  </head>
  <body>
    <div class="wrapper_content_page">
      <header>
        <div class="nav-list">
          <a href="../index.html" class="nav-link">Home Page</a>
          <a href="../research.html" class="nav-link">Research</a>
          <a href="../idea.html" class="nav-link">Ideology</a>
          <a href="../projects.html" class="nav-link">Projects</a>
          <div id="google_translate_element"></div> <!-- Translator here -->
        </div>

      </header>
      <section>
        <h1>Sub-Optimality Optimization</h1>
        <script type="text/javascript">
          // Initializes the Google Translate Element
          function googleTranslateElementInit() {
            new google.translate.TranslateElement({
              pageLanguage: 'en',
              includedLanguages: 'en,zh-CN,es,fr,de,ja,ru', // Restrict to English and Chinese Simplified
              layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
              autoDisplay: true  // Prevent automatic display of the dropdown
            }, 'google_translate_element');
          }
          // Function to manually trigger translation to Chinese
          function showTranslateOptions() {
            var selectField = document.querySelector(".goog-te-combo");
            if (selectField) {
              selectField.value = 'en,zh-CN,es,fr,de,ja,ru'; // Set the translation to Chinese
              selectField.dispatchEvent(new Event('change')); // Trigger the change event
            } else {
              console.error('Translation widget not loaded properly.');
            }
          }
          window.onload = function() {
                showTranslateOptions();
            };
          </script>          
        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
        <p></p>
        
        <!-- <blockquote>
          <p>The modern paradigm of machine learning puts the emphasis on the end result, 
            rather than the learning process, and overlooks a critical characteristic of human 
            learning: that it is robust to changing tasks and sequential experience.</p>
        </blockquote> -->

        <p>
          I am currently researching on the theoretical aspects of <strong>Continual Learning</strong> with advising from 
          professor <a href="https://scungao.github.io/" target="_blank">Sichun Gao</a> from UCSD Computer Science & Engineering Department.
          <!-- and professor <a href="https://talmopereira.com/" target="_blank">Talmo Pereira</a> in the Salk Institute.  -->
          I try to frame the general problem of Continual Learning from the perspective of Reinforcement Learning & Cognitive Neuroscience, hoping to develop algorithms that utilize the same strategies of "how we learn" onto an artificial agent.
          Moreover, I hope that such development can serve more than an engineering improvmenet, but rather contributing back to the neuroscience community to understand more about ourselves.
        </p>

        <p>
          I am developing a conceptual framework that may be used for families of algorithms and I am trying to build internal representations for artificial agents through designing a <strong>World Model</strong> (a forward model if we are specifcally looking at control problems), one similar to
          what we think the Cerabellum is doing in human brain, so their learned skills in one task can be modularized and transferable to other control tasks. The belows are some training results on classical control problems using 
          our <strong>Sub-Optiamlity Optimization (S.O.O.)</strong> algorithm (an adaptation using Supervised Forward Model and Proximal Policy Optimization). We are building explicit objectives that we want the model to learn (i.e. Forward Dynamics and Inverse Dynamics) 
          and applying supervised learning on these to achieve numerical representations. Embedding such representations into the model parameters implicitly aids the learning process.
        </p>
      
        <div style="text-align: center;">
          <img src="../assets/research/dynamics_model.png" alt="Fm-PPO" style="width:90%; height:auto;">
        </div>

        <a href="https://kbian.org/VNL-SoFM/" class="button">S.O.O. Documentation</a>

        <p></p>

      </section>
      <footer>
        <!-- <p>Â© 2024 Kaiwen Bian. All rights reserved.</p> -->
      </footer>
    </div>
    <script src="../javascripts/scale.fix.js"></script>
    <script src="../javascripts/translate.js"></script>
    <script src="../javascripts/mode.js"></script>
  </body>
</html>
