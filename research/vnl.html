<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Kaiwen Bian</title>

    <link rel="stylesheet" href="../stylesheets/styles.css">
    <link rel="stylesheet" href="../stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/KevinBian107/KevinBian107.github.io/main/assets/index/logo_3.png" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

  </head>
  <body>
    <div class="wrapper_content_page">
      <header>
        <div class="nav-list">
          <a href="../index.html" class="nav-link">Home Page</a>
          <a href="../research.html" class="nav-link">Research & Projects</a>
          <!-- <a href="../projects.html" class="nav-link">Projects</a> -->
          <div id="google_translate_element"></div> <!-- Translator here -->
        </div>

      </header>
      <section>
        <h1>Virtual Neural Lab - Tracking</h1>
        <script type="text/javascript">
          // Initializes the Google Translate Element
          function googleTranslateElementInit() {
            new google.translate.TranslateElement({
              pageLanguage: 'en',
              includedLanguages: 'en,zh-CN,es,fr,de,ja,ru', // Restrict to English and Chinese Simplified
              layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
              autoDisplay: true  // Prevent automatic display of the dropdown
            }, 'google_translate_element');
          }
          // Function to manually trigger translation to Chinese
          function showTranslateOptions() {
            var selectField = document.querySelector(".goog-te-combo");
            if (selectField) {
              selectField.value = 'en,zh-CN,es,fr,de,ja,ru'; // Set the translation to Chinese
              selectField.dispatchEvent(new Event('change')); // Trigger the change event
            } else {
              console.error('Translation widget not loaded properly.');
            }
          }
          window.onload = function() {
                showTranslateOptions();
            };
          </script>          
        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
        <p></p>

        <div class="time-glass">
          ðŸ“… Project Timeline: Dec 2023 - Now
        </div>

        <p>
          The brain captures such nature of information processing, capturing some ways that just happen to work. We are not trying to mimic the brain, but try to capture such 
          natural way of processing by using inspirations from brain. For an organism to exist today, it must be able to survive to pass on its genes. We believe that creating motion, interacting with the world, and making "output" is what the brain evolved to do: 
          it is what keeps us alive to pass the genes. Hence, we think that the capability to describe motions and behavior is really powerful; it is an integration of all computations from sensory to supervisory signals.
        </p>

        <p>
          I am working as an research intern at <a href="https://talmolab.org/" target="_blank">Talmo's Lab</a> in the Salk Institute. 
          We collaborate with <a href="https://www.oeb.harvard.edu/">Department of Organismic and Evolutionary Biology</a> at Harvard University, <a href="https://www.biology.washington.edu/">Department of Biology</a> at the University of Washington, and <a href="https://mila.quebec/en">Mila - Quebec AI Institute</a>, aiming to use 
          generative inverse kinetmatics imitation learning and goal-directed deep reinforcement learning to create highly efficient and parallelizable systems for computational models of the motor cortex.
      </p>

        <div style="text-align: center;">
            <img src="../assets/research/vnl_1.png" alt="Imitation pipeline" style="width:70%; height:auto;">
        </div>

        <blockquote>
            Abstract Deep Imitation Learning Idea (curtesy of Talmo's VNL slides)
        </blockquote>

        <p></p>

        <p>
            We believe that inverse kinematics imitation injects the basis layer alignment with biology to support more abstratc expolration of representations of the brain in artificial agents. Thus, we aim to 
            create pipelines with architectures and learning algorithms that are capable of generalizing and continual learning of low-level skills that are transferable for multiple higher-level 
            task-driven goals, trying to get closer to what the "real brain" is capable of doing.
        </p>

        <p></p>

        <div style="text-align: center;">
            <img src="../assets/research/Intentional_network.png" alt="Imitation pipeline" style="width:90%; height:auto;">
        </div>

        <blockquote>
            Deep imitation learning illustration (curtesy of VNL research strategy)
        </blockquote>

        <p></p>

        <p>
          Particularly we are interested in the motion of bio-mechanically realistic rodent model as we can use them (along with many motion captured CV data) to perhaps form an neural represenattion of how control is been done in the brain. 
          For the speed and computability, we use gpu based data-parrallelism training using Jax/Brax/Flax (Mimic-MJX) or cpu-based multi-node task-parralelism distributed training using Ray/Acme (VNL-Ray). For illustration purpose, here are some recent results that our team produced.
        </p>


        <div style="display: flex; justify-content: center; gap: 20px;">
          <img src="../assets/research/vnl_1.gif" alt="imitating rodent" style="width:45%; height:auto;">
          <img src="../assets/research/vnl_2.gif" alt="imitating humanoid" style="width:45%; height:auto;">
        </div>
        <p></p>

      <blockquote>
        <p>
          Left: An GPU/MJX trained PPO inverse kinematics imitation learning agent.
        </p>
        <p>
          Right: An Distributed-CPU/RAY trained DMPO inverse kinematics imitation learning agent.
        </p>
      </blockquote>

      <p></p>

      <p>
        More analysis of the learned representation (through a topological lens) was down in this  <a href="/research/tda.html">supplementary project</a>
      </p>

      <a href="https://github.com/talmolab/vnl-ray" class="button" >VNL-Ray</a>
      <a href="https://github.com/talmolab/track-mjx" class="button" >Mimic-MJX (Closed repo)</a>

      </section>
      <footer>
        <!-- <p>Â© 2024 Kaiwen Bian. All rights reserved.</p> -->
      </footer>
    </div>
    <script src="../javascripts/scale.fix.js"></script>
    <script src="../javascripts/translate.js"></script>
    <script src="../javascripts/mode.js"></script>
  </body>
</html>
