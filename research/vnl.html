<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Kaiwen Bian</title>

    <link rel="stylesheet" href="../stylesheets/styles.css">
    <link rel="stylesheet" href="../stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/KevinBian107/KevinBian107.github.io/main/assets/index/logo_3.png" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

  </head>
  <body>
    <div class="wrapper_content_page">
      <header>
        <div class="nav-list">
          <a href="../index.html" class="nav-link">Home Page</a>
          <a href="../research.html" class="nav-link">Research & Projects</a>
          <!-- <a href="../projects.html" class="nav-link">Projects</a> -->
          <div id="google_translate_element"></div> <!-- Translator here -->
        </div>

      </header>
      <section>
        <h1>Virtual Neural Lab - Tracking</h1>
        <script type="text/javascript">
          // Initializes the Google Translate Element
          function googleTranslateElementInit() {
            new google.translate.TranslateElement({
              pageLanguage: 'en',
              includedLanguages: 'en,zh-CN,es,fr,de,ja,ru', // Restrict to English and Chinese Simplified
              layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
              autoDisplay: true  // Prevent automatic display of the dropdown
            }, 'google_translate_element');
          }
          // Function to manually trigger translation to Chinese
          function showTranslateOptions() {
            var selectField = document.querySelector(".goog-te-combo");
            if (selectField) {
              selectField.value = 'en,zh-CN,es,fr,de,ja,ru'; // Set the translation to Chinese
              selectField.dispatchEvent(new Event('change')); // Trigger the change event
            } else {
              console.error('Translation widget not loaded properly.');
            }
          }
          window.onload = function() {
                showTranslateOptions();
            };
          </script>          
        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
        <p></p>

        <div class="time-glass">
          ðŸ“… Project Timeline: Dec 2023 - Now
        </div>

        <p>
          I am currently working as an undergraduate research intern at 
          <a href="https://talmolab.org/" target="_blank">Talmo's Lab</a> in the Salk Institute. We are working on the VNL project, 
          a collaboration between Salk Institute and Harvard University aiming to use advanced 
          <strong>Goal-directed Deep Reinforcement Learning</strong> methods & <strong>Generative Inverse Kinetmatics Imitation Learning</strong> to create imitation pipelines 
          for <strong>computational models of the brain</strong> using GPU accelerated Brax & JAX and multi-node distributed CPU training with Acme & Ray.
      </p>

      <a href="https://talmolab.org/" class="button" >Visit Our Lab Website</a>

      <p></p>

      <p>Maybe using a smart way of update may capture some innate characteristics of nature. 
        The brain captures such nature of information processing, capturing some ways that 
        just happen to work. We are not trying to mimic the brain, but try to capture such 
        natural way of processing by using inspirations from brain.
      </p>

        <div style="text-align: center;">
            <img src="../assets/research/vnl_1.png" alt="Imitation pipeline" style="width:70%; height:auto;">
        </div>

        <blockquote>
            Abstract Deep Imitation Learning Idea (curtesy of Talmo's VNL slides)
        </blockquote>

        <p></p>

        <p>
            For an organism to exist today, it must be able to survive to pass on its genes. We believe that Ethology is what the brain evolves to produce 
            and that it is guided by survival becasue one major function of neural mechanism is to produce actiuon, to interact with teh world, and to output. 
            It is about what we do. We think that the capability to describe behavior is really powerful. Motion is an integration of all computations from sensory to supervisory signals. 
            Brain does not output logits like neural netowrks, but neurons do get motion, which is muscle activation or torques in simple cases.
        </p>

        <p>
            We believe that inverse kinematics imitation injects the basis layer alignment with biology to support more abstratc expolration of representations of the brain in artificial agents. Thus, we aim to 
            create pipelines with architectures and learning algorithms that are capable of generalizing and continual learning of low-level skills that are transferable for multiple higher-level 
            task-driven goals, trying to get closer to what the "real brain" is capable of doing.
        </p>

        <p></p>

        <div style="text-align: center;">
            <img src="../assets/research/Intentional_network.png" alt="Imitation pipeline" style="width:90%; height:auto;">
        </div>

        <blockquote>
            Deep imitation learning illustration using encoder/decoder structure (curtesy of VNL Research Strategy)
        </blockquote>

        <p></p>

        <p>
          Particularly we are interested in the motion of bio-mechanically realistic rodent model as we can use them (along with many motion captured CV data) to perhaps form an neural represenattion of how control is been done in the brain. 
          For the speed and computability, we use gpu based data-parrallelism training using Jax/Brax/Flax or cpu-based multi-node task-parralelism distributed training using Ray/Acme. For illustration purpose, here are some recent results that our team produced.
        </p>


        <div style="display: flex; justify-content: center; gap: 20px;">
          <img src="../assets/research/vnl_1.gif" alt="imitating rodent" style="width:45%; height:auto;">
          <img src="../assets/research/vnl_2.gif" alt="imitating humanoid" style="width:45%; height:auto;">
        </div>
        <p></p>

      <blockquote>
        <p>
          Left: An GPU/MJX trained PPO inverse kinematics imitation learning agent.
        </p>
        <p>
          Right: An Distributed-CPU/RAY trained DMPO inverse kinematics imitation learning agent.
        </p>
      </blockquote>

      <p></p>

      <p>
        More analysis of the learned representation (through a topological lens) was down in this  <a href="/research/tda.html">supplementary project</a>
      </p>

      <a href="https://github.com/talmolab/vnl-ray" class="button" >VNL-Ray: an distributed-cpu training implementation of VNL</a>

      </section>
      <footer>
        <!-- <p>Â© 2024 Kaiwen Bian. All rights reserved.</p> -->
      </footer>
    </div>
    <script src="../javascripts/scale.fix.js"></script>
    <script src="../javascripts/translate.js"></script>
    <script src="../javascripts/mode.js"></script>
  </body>
</html>
