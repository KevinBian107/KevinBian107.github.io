<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Kaiwen Bian</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/KevinBian107/KevinBian107.github.io/main/assets/logo_3.png" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="index.html" target="_blank">Research</a></h1>
        <div class="nav-list">
          <a href="index.html" target="_blank">Home Page</a>
          <a href="repo.html" class="nav-link">View Active GitHub Repo</a>
          <a href="projects.html" class="nav-link">Data Science Projects</a>
          
          <button onclick="showTranslateOptions()" class="custom-translate-button">Translate</button>
          <div id="google_translate_element"></div>
          <script type="text/javascript">
            // Initializes the Google Translate Element
            function googleTranslateElementInit() {
              new google.translate.TranslateElement({
                pageLanguage: 'en',
                includedLanguages: 'zh-CN', // Restrict to English and Chinese Simplified
                layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
                autoDisplay: false  // Prevent automatic display of the dropdown
              }, 'google_translate_element');
            }
            // Function to manually trigger translation to Chinese
            function showTranslateOptions() {
              var selectField = document.querySelector(".goog-te-combo");
              if (selectField) {
                selectField.value = 'zh-CN'; // Set the translation to Chinese
                selectField.dispatchEvent(new Event('change')); // Trigger the change event
              } else {
                console.error('Translation widget not loaded properly.');
              }
            }
            </script>          
          <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
        
        </div>
        <blockquote>
          <p>"Searching for Needles in Haystacks"</p>
        </blockquote>
      </header>
      <section>
        <h1>Interships & Research</h1>

        <h2>UCSD CSE & Salk Institute Student Researcher</h2>
        
        <blockquote>
          <p>The modern paradigm of machine learning puts the emphasis on the end result, 
            rather than the learning process, and overlooks a critical characteristic of human 
            learning: that it is robust to changing tasks and sequential experience.</p>
        </blockquote>

        <p>
          I am currently researching into the theoretical aspects of <strong>Continual Learning</strong> with advising from professor 
          <a href="https://scungao.github.io/" target="_blank">Sichun Gao</a> from UCSD Computer Science & Engineering Department 
          and professor <a href="https://talmopereira.com/" target="_blank">Talmo Pereira</a> from Salk Institute. I try to frame the general problem of 
          Continual Learning from the perspective of Reinforcement Learning & Cognitive Neuroscience, hoping to develop algorithms 
          that utilize the same strategies of "how we learn" onto an artificial agent.
        </p>

        <div style="text-align: center;">
          <img src="assets/cl_1.png" alt="Continual Learning Schematic" style="width:100%; height:auto;">
        </div>

        <blockquote>
          <p>Schematic of Continual Learning (Zhang et al. (2024))</p>
        </blockquote>

        <a href="https://github.com/KevinBian107/Simple_CL_Env" class="button">Preliminary Simple Testing Environment</a>

        <p></p>

        <h2>Salk Institute Research Intern</h2>

        <p>
            I am currently working as an undergraduate research intern at 
            <a href="https://talmolab.org/" target="_blank">Talmo's Lab</a> in the Salk Institute. We are working on the VNL project, 
            a collaboration between Salk Institute and Harvard University aiming to use advanced 
            <strong>Deep Reinforcement Learning</strong> methods such as <strong>Imitation Learning</strong> to create working 
            pipelines for computational models of the brain using GPU accelerated JAX & Brax.
        </p>

        <div style="text-align: center;">
            <img src="assets/vnl_1.png" alt="Imitation pipeline" style="width:100%; height:auto;">
        </div>

        <blockquote>
            Abstract Deep Imitation Learning Idea (borrowed from Talmo's Lab VNL slides)
        </blockquote>

        <p></p>

        <p>
            We aim to create pipelines with architectures and learning algorithms that are capable of generalizing and 
            continual learning of low-level skills that are transferable for multiple higher-level task-driven goals, 
            trying to get closer to what the "real brain" is capable of doing.
        </p>

        <div style="text-align: center;">
            <img src="assets/Intentional_network.png" alt="Imitation pipeline" style="width:100%; height:auto;">
        </div>

        <blockquote>
            Deep imitation learning illustration using encoder/decoder structure (borrowed from VNL Research Strategy)
        </blockquote>

        <p></p>

        <p>For demo purposes, here is an easy version of what we do in our lab: 
          self-learning (proprioception data DRL trained) Brax ant.
        </p>

        <div style="text-align: center; max-width: 100%;">
          <video controls style="width: 100%; height: auto;">
              <source src="assets/cross_gap_vision_0.1.mp4" type="video/mp4">
              Your browser does not support the video tag.
          </video>
        </div>

        <blockquote>
          <p>Using custom dm_control env and Proximal Policy Control for training</p>
        </blockquote>

        <a href="https://talmolab.org/" class="button" >Visit Our Lab Website</a>

        <p></p>

        <h2>UCSD FMP Research Scholar</h2>

        <p>
            I researched on Affordance Embodied Simulation’s presences in <strong>Multimodal Models</strong> through the UCSD Faculty Mentorship Program (Sep 2023 - Jun 2024) under the supervision of 
            <a href="https://seantrott.github.io/">Sean Trott</a>. We try to improve the reliability of machine learning models through examining the degree of models’ “understanding” of the subtle 
            keys in human languages and how it is used to map the world we know.
        </p>

        <a href="https://github.com/KevinBian107/mllm_embodied_simulation" class="button" >Visit Project GitHub!</a>

        <p></p>

      </section>
      <footer>
        <p>© 2024 Kaiwen Bian. All rights reserved.</p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script src="javascripts/translate.js"></script>
  </body>
</html>
